1. start BCI process
    -> return only once BCI process is ready
    -> update ci_processes_state shared variable which stores
        {process_id: {character, phase, frequency, q, config_id, collecting}}
    -> in stream.py, create Configuration object and store in shared dict
    -> write config_id into bci_processes_states[os.getpid()]

-> Laurence already started it in his branch for 2 and 3 checkout to his branch and rebase main
2. when frontend signals a character we are going to collect for
    -> sends POST to backend (character, frequency, phase)
    -> update the bci_processes_states by updating (character, frequency, phase)
    -> turn collecting to True
    
    
    
    -> initialize (character, frequency, phase, COLLECTING) push it to deque.
    -> stream.py pop_front from deque, process the object while the state is COLLECTING
    -> set the shared variable "collecting" to true in order to start collecting in the bci process.

3. when frontend highlights character for second time
    -> flush everything inside of bci_processes_states[os.getpid()] queue
    -> set the shared variable "collecting" to False in order to stop collecting in the bci process.
    
    
    -> modify the state of the first object to be WRITING
    -> clear the shared queue and write to database
    -> 

   -> [] <-
    
4. stop BCI process
    -> stop the BCI process



"""
Ideas for scaling
collect: character, frequency, phase
write: if not collecting can write
shared_dict {character: object_, character: object_}

create Collection instance from parent and pass it to child

class CollectionInstance:
    character
    phase
    frequency
    queue
    state = "COLLECTION"/"WRITING"

-> e.g. hit route 3
we pass the collectionInstance, write function that does asynchronously
and process the next CollectionInstance object...
"""
